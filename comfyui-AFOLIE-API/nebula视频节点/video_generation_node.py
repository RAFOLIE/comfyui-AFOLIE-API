"""
Nebula è§†é¢‘ç”ŸæˆèŠ‚ç‚¹
æ”¯æŒå¤šç§æ¨¡å‹ï¼šSora 2, Veo, é˜¿é‡Œä¸‡ç›¸, è±†åŒ… Seedance
"""

from __future__ import annotations

import base64
import os
import sys
import time
import io
import tempfile
from typing import Dict, Any, Optional, List, Tuple

import torch
import numpy as np
import requests

MODULE_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR = os.path.dirname(MODULE_DIR)
if MODULE_DIR not in sys.path:
    sys.path.insert(0, MODULE_DIR)
if PARENT_DIR not in sys.path:
    sys.path.insert(0, PARENT_DIR)

try:
    from server import PromptServer
except ImportError:
    class _DummyPromptServer:
        instance = None
    PromptServer = _DummyPromptServer()

import comfy.utils
import comfy.model_management

try:
    from nebula_logger import logger
except ImportError:
    logger = None

try:
    from nebula_config_manager import ConfigManager
except ImportError:
    ConfigManager = None

from nebula_video_client import VideoClient, VideoModel


class VideoGenerationNode:
    """
    Nebula è§†é¢‘ç”ŸæˆèŠ‚ç‚¹
    æ”¯æŒæ–‡ç”Ÿè§†é¢‘ã€å›¾ç”Ÿè§†é¢‘
    """

    RETURN_TYPES = ("VIDEO", "STRING")
    RETURN_NAMES = ("video", "info")
    FUNCTION = "generate"
    OUTPUT_NODE = True
    CATEGORY = "AFOLIE/API/è§†é¢‘èŠ‚ç‚¹"

    # å¯ç”¨æ¨¡å‹åˆ—è¡¨
    MODELS = [
        "sora-2",
        "veo-3.0-fast-generate-001",
        "veo-3.1-fast-generate-preview",
        "wan2.5-t2v-preview",
        "wan2.5-i2v-preview",
        "doubao-seedance-1-0-lite-t2v-250428",
        "doubao-seedance-1-0-lite-i2v-250428",
        "doubao-seedance-1-0-pro-250528",
    ]

    def __init__(self):
        self.interrupt_checker = comfy.model_management.throw_exception_if_processing_interrupted
        if ConfigManager:
            self.config_manager = ConfigManager(PARENT_DIR)
        else:
            self.config_manager = None

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä¸€åªå¯çˆ±çš„å°çŒ«åœ¨èŠ±å›­é‡Œç©è€ï¼Œé˜³å…‰æ˜åªšï¼Œç”»é¢æ¸©é¦¨",
                    "tooltip": "è§†é¢‘ç”Ÿæˆæç¤ºè¯"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "tooltip": "API å¯†é’¥ï¼ˆå¯é€‰ï¼Œå¯ç”¨ config.ini é…ç½®ï¼‰"
                }),
                "model": (cls.MODELS, {
                    "default": "sora-2",
                    "tooltip": "é€‰æ‹©è§†é¢‘ç”Ÿæˆæ¨¡å‹"
                }),
                "ä»»åŠ¡æ¨¡å¼": (["ä»…æäº¤", "æäº¤å¹¶ç­‰å¾…å®Œæˆ"], {
                    "default": "æäº¤å¹¶ç­‰å¾…å®Œæˆ",
                    "tooltip": "ä»…æäº¤ï¼šè¿”å›ä»»åŠ¡IDï¼Œå¯ç”¨äºåç»­æŸ¥è¯¢ï¼›æäº¤å¹¶ç­‰å¾…å®Œæˆï¼šç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆ"
                }),
            },
            "optional": {
                "è¾“å…¥å›¾åƒ": ("IMAGE", {
                    "tooltip": "å‚è€ƒå›¾åƒï¼ˆå›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼‰"
                }),
                "å°¾å¸§å›¾åƒ": ("IMAGE", {
                    "tooltip": "å°¾å¸§å›¾åƒï¼ˆä»… Veo 3.1 å’Œè±†åŒ…æ”¯æŒï¼‰"
                }),
                "è§†é¢‘æ—¶é•¿": ("INT", {
                    "default": 5,
                    "min": 1,
                    "max": 60,
                    "tooltip": "è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œæ ¹æ®æ¨¡å‹ä¸åŒæ”¯æŒèŒƒå›´ä¸åŒ"
                }),
                "åˆ†è¾¨ç‡": (["720p", "480p", "1080p", "4k"], {
                    "default": "720p",
                    "tooltip": "è§†é¢‘åˆ†è¾¨ç‡"
                }),
                "å®½é«˜æ¯”": (["16:9", "9:16", "1:1", "4:3", "3:4", "21:9", "adaptive"], {
                    "default": "16:9",
                    "tooltip": "è§†é¢‘å®½é«˜æ¯”ï¼Œadaptive ä»…éƒ¨åˆ†æ¨¡å‹æ”¯æŒ"
                }),
                "å¸§ç‡": ("INT", {
                    "default": 24,
                    "min": 12,
                    "max": 60,
                    "tooltip": "å¸§ç‡ï¼ˆfpsï¼‰"
                }),
                "éšæœºç§å­": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647,
                    "tooltip": "éšæœºç§å­ï¼ˆ-1 ä¸ºéšæœºï¼Œå›ºå®šå€¼å¯å¤ç°ï¼‰"
                }),
                "ç”ŸæˆéŸ³é¢‘": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦ç”ŸæˆåŒæ­¥éŸ³é¢‘"
                }),
                "æ·»åŠ æ°´å°": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"
                }),
                "äººåƒç”Ÿæˆ": (["allow_all", "allow_adult", "dont_allow"], {
                    "default": "allow_all",
                    "tooltip": "äººåƒç”Ÿæˆç­–ç•¥ï¼ˆä»… Veoï¼‰"
                }),
                "ç”Ÿæˆæ•°é‡": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 4,
                    "tooltip": "æ¯æ¬¡ç”Ÿæˆçš„è§†é¢‘æ•°é‡ï¼ˆä»… Veoï¼‰"
                }),
                "Remixè§†é¢‘ID": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "tooltip": "åŸºäºå·²æœ‰è§†é¢‘é‡æ–°ç”Ÿæˆï¼ˆä»… Sora 2 Remix æ¨¡å¼ï¼Œéœ€ä»¥ video_ å¼€å¤´ï¼‰"
                }),
                "è±†åŒ…æç¤ºè¯": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "tooltip": "è±†åŒ…ä¸“ç”¨æç¤ºè¯æ ¼å¼ï¼ˆæ”¯æŒ --ratio --dur --rs ç­‰å‚æ•°ï¼‰"
                }),
                "è½®è¯¢é—´éš”": ("FLOAT", {
                    "default": 5.0,
                    "min": 1.0,
                    "max": 60.0,
                    "step": 1.0,
                    "tooltip": "è½®è¯¢æŸ¥è¯¢é—´éš”ï¼ˆç§’ï¼‰"
                }),
                "æœ€å¤§ç­‰å¾…æ—¶é—´": ("INT", {
                    "default": 3600,
                    "min": 60,
                    "max": 7200,
                    "tooltip": "æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰"
                }),
            }
        }

    @staticmethod
    def _ensure_not_interrupted():
        comfy.model_management.throw_exception_if_processing_interrupted()

    def _resolve_api_key(self, provided_key: str) -> str:
        """è§£æ API Key"""
        raw_key = (provided_key or "").strip()
        if not raw_key and self.config_manager:
            resolved_key = self.config_manager.sanitize_api_key(
                self.config_manager.load_api_key()
            )
            if not resolved_key:
                raise ValueError("è¯·é…ç½®æœ‰æ•ˆçš„ API Keyï¼ˆåœ¨ config.ini æˆ–èŠ‚ç‚¹è¾“å…¥ä¸­ï¼‰")
            return resolved_key
        elif raw_key:
            if self.config_manager:
                raw_key = self.config_manager.sanitize_api_key(raw_key)
            return raw_key
        else:
            raise ValueError("è¯·é…ç½®æœ‰æ•ˆçš„ API Keyï¼ˆåœ¨ config.ini æˆ–èŠ‚ç‚¹è¾“å…¥ä¸­ï¼‰")

    def _image_to_base64(self, image_tensor: torch.Tensor) -> str:
        """å°†å›¾åƒå¼ é‡è½¬æ¢ä¸º Base64 ç¼–ç """
        if image_tensor is None:
            return ""

        # è½¬æ¢ä¸º numpy æ•°ç»„
        image_np = image_tensor.cpu().numpy()

        # ç¡®ä¿å½¢çŠ¶æ­£ç¡® [B, H, W, C]
        if len(image_np.shape) == 3:
            image_np = np.expand_dims(image_np, 0)

        # å–ç¬¬ä¸€å¼ å›¾
        image_np = image_np[0]

        # è½¬æ¢ä¸º uint8
        if image_np.dtype != np.uint8:
            image_np = (image_np * 255).astype(np.uint8)

        # è½¬æ¢ä¸º RGB
        if image_np.shape[-1] == 4:
            image_np = image_np[:, :, :3]

        # è½¬æ¢ä¸º bytes å¹¶ç¼–ç ä¸º base64
        import io
        from PIL import Image

        pil_image = Image.fromarray(image_np)
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        image_bytes = buffer.getvalue()
        base64_str = base64.b64encode(image_bytes).decode('utf-8')

        return f"data:image/png;base64,{base64_str}"

    def _get_api_base_url(self) -> str:
        """è·å– API Base URL"""
        if self.config_manager:
            return self.config_manager.get_effective_api_base_url()
        return "https://llm.ai-nebula.com"

    def _build_doubao_metadata(
        self,
        prompt: str,
        first_frame: Optional[str] = None,
        last_frame: Optional[str] = None,
        reference_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """æ„å»ºè±†åŒ… Seedance çš„ metadata æ ¼å¼"""
        content = []

        # æ·»åŠ æ–‡æœ¬æç¤ºè¯
        if prompt:
            content.append({
                "type": "text",
                "text": prompt
            })

        # æ·»åŠ é¦–å¸§
        if first_frame:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": first_frame
                },
                "role": "first_frame"
            })

        # æ·»åŠ å°¾å¸§
        if last_frame:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": last_frame
                },
                "role": "last_frame"
            })

        # æ·»åŠ å‚è€ƒå›¾
        if reference_images:
            for ref_img in reference_images:
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": ref_img
                    },
                    "role": "reference_image"
                })

        return {"content": content}

    def generate(
        self,
        prompt: str,
        api_key: str,
        model: str,
        ä»»åŠ¡æ¨¡å¼: str = "æäº¤å¹¶ç­‰å¾…å®Œæˆ",
        è¾“å…¥å›¾åƒ: Optional[torch.Tensor] = None,
        å°¾å¸§å›¾åƒ: Optional[torch.Tensor] = None,
        è§†é¢‘æ—¶é•¿: int = 5,
        åˆ†è¾¨ç‡: str = "720p",
        å®½é«˜æ¯”: str = "16:9",
        å¸§ç‡: int = 24,
        éšæœºç§å­: int = -1,
        ç”ŸæˆéŸ³é¢‘: bool = False,
        æ·»åŠ æ°´å°: bool = False,
        äººåƒç”Ÿæˆ: str = "allow_all",
        ç”Ÿæˆæ•°é‡: int = 1,
        Remixè§†é¢‘ID: str = "",
        è±†åŒ…æç¤ºè¯: str = "",
        è½®è¯¢é—´éš”: float = 5.0,
        æœ€å¤§ç­‰å¾…æ—¶é—´: int = 3600,
    ) -> Tuple[Dict[str, Any], str]:
        """ç”Ÿæˆè§†é¢‘"""
        start_time = time.time()

        try:
            self._ensure_not_interrupted()

            # è§£æ API Key
            resolved_api_key = self._resolve_api_key(api_key)

            # è·å– API Base URL
            api_base_url = self._get_api_base_url()

            # åˆ›å»ºå®¢æˆ·ç«¯
            client = VideoClient(
                api_base_url=api_base_url,
                api_key=resolved_api_key,
                interrupt_checker=self._ensure_not_interrupted
            )

            # å‡†å¤‡å›¾åƒ
            image_base64 = None
            if è¾“å…¥å›¾åƒ is not None:
                image_base64 = self._image_to_base64(è¾“å…¥å›¾åƒ)

            last_frame_base64 = None
            if å°¾å¸§å›¾åƒ is not None:
                last_frame_base64 = self._image_to_base64(å°¾å¸§å›¾åƒ)

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": model,
            }

            # å¤„ç†è±†åŒ…æ¨¡å‹çš„ç‰¹æ®Šæ ¼å¼
            if model.startswith("doubao"):
                # ä½¿ç”¨è±†åŒ…ä¸“ç”¨æç¤ºè¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ™®é€šæç¤ºè¯
                effective_prompt = è±†åŒ…æç¤ºè¯ if è±†åŒ…æç¤ºè¯ else prompt

                # æ„å»ºè±†åŒ… metadata
                metadata = self._build_doubao_metadata(
                    prompt=effective_prompt,
                    first_frame=image_base64,
                    last_frame=last_frame_base64
                )
                request_params["metadata"] = metadata
            else:
                # å…¶ä»–æ¨¡å‹ä½¿ç”¨æ ‡å‡† prompt
                request_params["prompt"] = prompt
                if image_base64:
                    request_params["image"] = image_base64

            # æ·»åŠ é€šç”¨å‚æ•°
            if éšæœºç§å­ >= 0:
                request_params["seed"] = éšæœºç§å­

            # Sora 2 ä¸“ç”¨å‚æ•°
            if model == "sora-2":
                size_map = {
                    "16:9": "1280x720",
                    "9:16": "720x1280",
                }
                request_params["seconds"] = str(è§†é¢‘æ—¶é•¿)
                request_params["size"] = size_map.get(å®½é«˜æ¯”, "1280x720")
                if image_base64:
                    request_params["input_reference"] = image_base64
                if Remixè§†é¢‘ID and Remixè§†é¢‘ID.startswith("video_"):
                    request_params["remix_from_video_id"] = Remixè§†é¢‘ID

            # Veo ä¸“ç”¨å‚æ•°
            elif model.startswith("veo"):
                request_params["duration_seconds"] = è§†é¢‘æ—¶é•¿
                request_params["aspect_ratio"] = å®½é«˜æ¯”
                request_params["resolution"] = åˆ†è¾¨ç‡
                request_params["fps"] = å¸§ç‡
                request_params["generate_audio"] = ç”ŸæˆéŸ³é¢‘
                request_params["person_generation"] = äººåƒç”Ÿæˆ
                request_params["add_watermark"] = æ·»åŠ æ°´å°
                request_params["sample_count"] = ç”Ÿæˆæ•°é‡
                if last_frame_base64 and "veo-3.1" in model:
                    request_params["last_frame"] = last_frame_base64

            # é˜¿é‡Œä¸‡ç›¸ä¸“ç”¨å‚æ•°
            elif model.startswith("wan"):
                request_params["duration"] = è§†é¢‘æ—¶é•¿
                request_params["resolution"] = åˆ†è¾¨ç‡
                if model == "wan2.5-t2v-preview":
                    size_map = {
                        "16:9": "1280*720",
                        "9:16": "720*1280",
                        "1:1": "1080*1080",
                    }
                    request_params["size"] = size_map.get(å®½é«˜æ¯”, "1280*720")

            # è®°å½•æ—¥å¿—
            if logger:
                logger.header("ğŸ¬ Nebula è§†é¢‘ç”Ÿæˆä»»åŠ¡")
                logger.info(f"æ¨¡å‹: {model}")
                logger.info(f"ä»»åŠ¡æ¨¡å¼: {ä»»åŠ¡æ¨¡å¼}")
                logger.info(f"è§†é¢‘æ—¶é•¿: {è§†é¢‘æ—¶é•¿}ç§’")
                logger.info(f"åˆ†è¾¨ç‡: {åˆ†è¾¨ç‡}")
                logger.info(f"å®½é«˜æ¯”: {å®½é«˜æ¯”}")
                if è¾“å…¥å›¾åƒ is not None:
                    logger.info("å›¾ç”Ÿè§†é¢‘æ¨¡å¼: å¯ç”¨")
                logger.separator()

            # æäº¤ä»»åŠ¡
            submit_result = client.submit_video_task(**request_params)
            task_id = submit_result.get("task_id", "")

            if not task_id:
                raise RuntimeError("æœªè¿”å›ä»»åŠ¡ ID")

            submit_time = time.time() - start_time

            # ä»…æäº¤æ¨¡å¼
            if ä»»åŠ¡æ¨¡å¼ == "ä»…æäº¤":
                info_text = f"âœ… ä»»åŠ¡å·²æäº¤\n"
                info_text += f"ä»»åŠ¡ ID: {task_id}\n"
                info_text += f"æ¨¡å‹: {model}\n"
                info_text += f"æäº¤è€—æ—¶: {submit_time:.2f}s\n\n"
                info_text += f"ğŸ’¡ è¯·ä½¿ç”¨'æŸ¥è¯¢è§†é¢‘ä»»åŠ¡'èŠ‚ç‚¹æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"

                return (None, info_text)

            # ç­‰å¾…å®Œæˆæ¨¡å¼
            if logger:
                logger.info(f"ä»»åŠ¡ ID: {task_id}")
                logger.info(f"å¼€å§‹è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ...")

            # è¿›åº¦å›è°ƒå‡½æ•°
            def progress_callback(result: Dict[str, Any], elapsed: float):
                status = result.get("status", "unknown")
                if logger and status not in ["submitted", "processing"]:
                    logger.info(f"ä»»åŠ¡çŠ¶æ€: {status} (å·²ç­‰å¾… {elapsed:.0f}s)")

            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            result = client.wait_for_task_completion(
                task_id=task_id,
                poll_interval=è½®è¯¢é—´éš”,
                max_wait_time=æœ€å¤§ç­‰å¾…æ—¶é—´,
                progress_callback=progress_callback
            )

            total_time = time.time() - start_time

            # æå–è§†é¢‘ URL
            video_url = ""
            if "video" in result:
                video_data = result["video"]
                if isinstance(video_data, dict) and "url" in video_data:
                    video_url = video_data["url"]
                elif isinstance(video_data, str):
                    video_url = video_data

            # ä¸‹è½½è§†é¢‘
            video_path = ""
            if video_url:
                if logger:
                    logger.info(f"æ­£åœ¨ä¸‹è½½è§†é¢‘: {video_url[:80]}...")
                
                self._ensure_not_interrupted()
                
                try:
                    response = requests.get(video_url, timeout=120, verify=True)
                    response.raise_for_status()
                    
                    video_bytes = response.content
                    
                    if logger:
                        logger.info(f"è§†é¢‘ä¸‹è½½æˆåŠŸ: {len(video_bytes)} å­—èŠ‚")
                    
                    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶è·¯å¾„
                    temp_dir = tempfile.gettempdir()
                    video_filename = f"nebula_{task_id}.mp4"
                    video_path = os.path.join(temp_dir, video_filename)
                    
                    with open(video_path, 'wb') as f:
                        f.write(video_bytes)
                    
                    if logger:
                        logger.info(f"è§†é¢‘å·²ä¿å­˜: {video_path}")
                except Exception as e:
                    if logger:
                        logger.error(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {str(e)}")
                    info_text += f"\nâš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥: {str(e)}"

            # æ„å»ºè¿”å›ä¿¡æ¯
            info_text = f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ\n"
            info_text += f"ä»»åŠ¡ ID: {task_id}\n"
            info_text += f"æ¨¡å‹: {model}\n"
            info_text += f"è§†é¢‘æ—¶é•¿: {è§†é¢‘æ—¶é•¿}ç§’\n"
            info_text += f"åˆ†è¾¨ç‡: {åˆ†è¾¨ç‡}\n"
            info_text += f"å®½é«˜æ¯”: {å®½é«˜æ¯”}\n"
            info_text += f"æ€»è€—æ—¶: {total_time:.2f}s\n"
            if video_url:
                info_text += f"è§†é¢‘é“¾æ¥: {video_url[:100]}..."

            if logger:
                logger.summary("ä»»åŠ¡å®Œæˆ", {
                    "ä»»åŠ¡ID": task_id,
                    "æ€»è€—æ—¶": f"{total_time:.2f}s",
                    "è§†é¢‘": "å·²ä¸‹è½½" if video_path else "æœªä¸‹è½½"
                })

            return (video_path or None, info_text)

        except comfy.model_management.InterruptProcessingException:
            if logger:
                logger.warning("ä»»åŠ¡å·²å–æ¶ˆ")
            raise
        except Exception as e:
            error_msg = str(e)[:500]
            if logger:
                logger.error(f"ç”Ÿæˆå¤±è´¥: {error_msg}")
            info_text = f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥\n\né”™è¯¯ä¿¡æ¯: {error_msg}"
            return (None, info_text)


class VideoQueryNode:
    """
    Nebula è§†é¢‘ä»»åŠ¡æŸ¥è¯¢èŠ‚ç‚¹
    """

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("task_id", "info")
    FUNCTION = "query"
    OUTPUT_NODE = False
    CATEGORY = "AFOLIE/API/è§†é¢‘èŠ‚ç‚¹"

    def __init__(self):
        self.interrupt_checker = comfy.model_management.throw_exception_if_processing_interrupted
        if ConfigManager:
            self.config_manager = ConfigManager(PARENT_DIR)
        else:
            self.config_manager = None

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "task_id": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "tooltip": "ä»»åŠ¡ IDï¼ˆä»¥ video_ å¼€å¤´ï¼‰"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "tooltip": "API å¯†é’¥ï¼ˆå¯é€‰ï¼Œå¯ç”¨ config.ini é…ç½®ï¼‰"
                }),
            },
        }

    def _resolve_api_key(self, provided_key: str) -> str:
        """è§£æ API Key"""
        raw_key = (provided_key or "").strip()
        if not raw_key and self.config_manager:
            resolved_key = self.config_manager.sanitize_api_key(
                self.config_manager.load_api_key()
            )
            if not resolved_key:
                raise ValueError("è¯·é…ç½®æœ‰æ•ˆçš„ API Keyï¼ˆåœ¨ config.ini æˆ–èŠ‚ç‚¹è¾“å…¥ä¸­ï¼‰")
            return resolved_key
        elif raw_key:
            if self.config_manager:
                raw_key = self.config_manager.sanitize_api_key(raw_key)
            return raw_key
        else:
            raise ValueError("è¯·é…ç½®æœ‰æ•ˆçš„ API Keyï¼ˆåœ¨ config.ini æˆ–èŠ‚ç‚¹è¾“å…¥ä¸­ï¼‰")

    def _get_api_base_url(self) -> str:
        """è·å– API Base URL"""
        if self.config_manager:
            return self.config_manager.get_effective_api_base_url()
        return "https://llm.ai-nebula.com"

    def query(
        self,
        task_id: str,
        api_key: str,
    ) -> Tuple[str, str]:
        """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
        try:
            self._ensure_not_interrupted()

            # è§£æ API Key
            resolved_api_key = self._resolve_api_key(api_key)

            # è·å– API Base URL
            api_base_url = self._get_api_base_url()

            # åˆ›å»ºå®¢æˆ·ç«¯
            client = VideoClient(
                api_base_url=api_base_url,
                api_key=resolved_api_key,
                interrupt_checker=self._ensure_not_interrupted
            )

            # æŸ¥è¯¢ä»»åŠ¡
            result = client.query_video_task(task_id)

            # æ„å»ºè¿”å›ä¿¡æ¯
            status = result.get("status", "unknown")
            info_text = f"ä»»åŠ¡ ID: {task_id}\n"
            info_text += f"çŠ¶æ€: {status}\n"

            # æå–è§†é¢‘ URL
            video_url = ""
            if "video" in result:
                video_data = result["video"]
                if isinstance(video_data, dict) and "url" in video_data:
                    video_url = video_data["url"]
                elif isinstance(video_data, str):
                    video_url = video_data
                if video_url:
                    info_text += f"è§†é¢‘é“¾æ¥: {video_url[:100]}..."

            if "error" in result:
                info_text += f"\né”™è¯¯ä¿¡æ¯: {result['error']}"

            return (task_id, info_text)

        except Exception as e:
            error_msg = str(e)[:500]
            info_text = f"âŒ æŸ¥è¯¢å¤±è´¥\n\né”™è¯¯ä¿¡æ¯: {error_msg}"
            return (task_id, info_text)

    @staticmethod
    def _ensure_not_interrupted():
        comfy.model_management.throw_exception_if_processing_interrupted()


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "AFOLIE_VideoGeneration": VideoGenerationNode,
    "AFOLIE_VideoQuery": VideoQueryNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AFOLIE_VideoGeneration": "ğŸ¬ AFOLIE Nebula è§†é¢‘ç”Ÿæˆ",
    "AFOLIE_VideoQuery": "ğŸ” AFOLIE æŸ¥è¯¢è§†é¢‘ä»»åŠ¡",
}
